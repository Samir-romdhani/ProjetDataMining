{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "\n",
    "# plotly configuration\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\",\"comment\", \"emotion\", \"date\",\"url\"])\n",
    "            self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\"])]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"comment\"],dtype={\"id\":\"int64\",\"text\":\"str\"},nrows=4000)\n",
    "            not_null_text = 1 ^ pd.isnull(self.data[\"comment\"])\n",
    "            not_null_id = 1 ^ pd.isnull(self.data[\"id\"])\n",
    "            self.data = self.data.loc[not_null_id & not_null_text, :]\n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange, pk l'connexion ,ma@ t7ebech temc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoum 3adet fourfi 900 ta3 7 jour ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>N7eb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment   emotion  \\\n",
       "0   0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1   1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2   2  brabi orange, pk l'connexion ,ma@ t7ebech temc...  negative   \n",
       "3   3  slm orange elyoum 3adet fourfi 900 ta3 7 jour ...  negative   \n",
       "4   4                                        N7eb orange  positive   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Initialize()\n",
    "data.initialize(\"data\\\\four-column500v1.4.csv\")\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.processed_data\n",
    "neg = len(df[df[\"emotion\"] == \"negative\"])\n",
    "pos = len(df[df[\"emotion\"] == \"positive\"])\n",
    "#neu = len(df[df[\"emotion\"] == \"neutral\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"negative\",\"positive\"],\n",
    "        y=[neg, pos],\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PostCleanuper:\n",
    "    def iterate(self):\n",
    "        for cleanup_method in [self.remove_urls,\n",
    "                               self.remove_usernames,\n",
    "                               self.remove_na,\n",
    "                               self.remove_special_chars,\n",
    "                               self.remove_numbers]:\n",
    "            yield cleanup_method\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_by_regex(tweets, regexp):\n",
    "        tweets.loc[:, \"comment\"].replace(regexp, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_urls(self, tweets):\n",
    "        return PostCleanuper.remove_by_regex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_na(self, tweets):\n",
    "        return tweets[tweets[\"comment\"] != \"Not Available\"]\n",
    "\n",
    "    def remove_special_chars(self, tweets):  # it unrolls the hashtags to normal words\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "            tweets.loc[:, \"comment\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_usernames(self, tweets):\n",
    "        return PostCleanuper.remove_by_regex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_numbers(self, tweets):\n",
    "        return PostCleanuper.remove_by_regex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Cleansing(Data_Initialize):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def cleanup(self, cleanuper):\n",
    "        t = self.processed_data\n",
    "        for cleanup_method in cleanuper.iterate():\n",
    "            if not self.is_testing:\n",
    "                t = cleanup_method(t)\n",
    "            else:\n",
    "                if cleanup_method.__name__ != \"remove_na\":\n",
    "                    t = cleanup_method(t)\n",
    "\n",
    "        self.processed_data = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange pk lconnexion ma tebech temchili ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoumadet fourfi ta jour tantli ma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Neb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment   emotion  \\\n",
       "0   0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1   1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2   2  brabi orange pk lconnexion ma tebech temchili ...  negative   \n",
       "3   3  slm orange elyoumadet fourfi ta jour tantli ma...  negative   \n",
       "4   4                                         Neb orange  positive   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Cleansing(data)\n",
    "data.cleanup(PostCleanuper())\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_TokenStem(Data_Cleansing):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"comment\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"comment\"]))\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"comment\"] = tokenizer(row[\"comment\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"comment\"]\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['في_بيتنا',\n",
       " 'كل',\n",
       " 'شي',\n",
       " 'لما',\n",
       " 'تحتاجه',\n",
       " 'يضيع',\n",
       " '...',\n",
       " 'ادور',\n",
       " 'على',\n",
       " 'شاحن',\n",
       " 'فجأة',\n",
       " 'يختفي']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize('في_بيتنا كل شي لما تحتاجه يضيع ...ادور على شاحن فجأة يختفي  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[brabi, orang, pk, lconnexion, ma, tebech, tem...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[brabi, orange, pk, lconnexion, ma, tebech, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[slm, orang, elyoumadet, fourfi, ta, jour, tan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[slm, orange, elyoumadet, fourfi, ta, jour, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[neb, orang]</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "      <td>[Neb, orange]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment   emotion  \\\n",
       "0   0  [عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...  negative   \n",
       "1   1  [اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...  negative   \n",
       "2   2  [brabi, orang, pk, lconnexion, ma, tebech, tem...  negative   \n",
       "3   3  [slm, orang, elyoumadet, fourfi, ta, jour, tan...  negative   \n",
       "4   4                                       [neb, orang]  positive   \n",
       "\n",
       "                       date  \\\n",
       "0  2018-01-02T19:16:17+0000   \n",
       "1  2018-01-02T19:43:48+0000   \n",
       "2  2018-01-02T20:37:47+0000   \n",
       "3  2018-01-02T19:00:49+0000   \n",
       "4  2018-01-08T20:13:49+0000   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.facebook.com/298166859034_10155976...   \n",
       "1  https://www.facebook.com/298166859034_10155976...   \n",
       "2  https://www.facebook.com/298166859034_10155976...   \n",
       "3  https://www.facebook.com/298166859034_10155976...   \n",
       "4  https://www.facebook.com/298166859034_10155991...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...  \n",
       "1  [اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...  \n",
       "2  [brabi, orange, pk, lconnexion, ma, tebech, te...  \n",
       "3  [slm, orange, elyoumadet, fourfi, ta, jour, ta...  \n",
       "4                                      [Neb, orange]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_TokenStem(data)\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\"Building the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merci', 196), ('orang', 137), ('و', 72), ('في', 72), ('w', 63)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.index:\n",
    "    words.update(data.processed_data.loc[idx, \"comment\"])\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merci', 196), ('orang', 137), ('و', 72), ('في', 72), ('w', 63)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Wordlist(Data_TokenStem):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    whitelist = [\"n't\",\"not\"]\n",
    "    wordlist = []\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=3, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        import os\n",
    "        if os.path.isfile(\"data\\\\wordlistv1.4.csv\"):\n",
    "            word_df = pd.read_csv(\"data\\\\wordlistv1.4.csv\",encoding=\"latin-1\")\n",
    "            word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "            self.wordlist = list(word_df.loc[:, \"word\"])\n",
    "            return\n",
    "\n",
    "        words = Counter()\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"comment\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"data\\\\wordlistv1.4.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Data_Wordlist(data)\n",
    "data.build_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"data\\\\wordlistv1.4.csv\", encoding=\"latin-1\")\n",
    "x_words = list(words.loc[0:5,\"word\"])\n",
    "x_words.reverse()\n",
    "y_occ = list(words.loc[0:5,\"occurrences\"])\n",
    "y_occ.reverse()\n",
    "\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=y_occ,\n",
    "        y=x_words,\n",
    "        orientation=\"h\"\n",
    ")]\n",
    "#plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Top words in built wordlist\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import codecs\n",
    "#with codecs.open(\"data\\\\wordlistv1.4.csv\", \"r\",encoding='utf-8', errors='ignore') as fdata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(\"data\\\\wordlist.csv\", encoding=\"latin-1\") as datafile:\n",
    "#words = pd.read_csv(\"data\\\\wordlistv1.4.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 6 artists>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebd309ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x_words,y_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_BagOfWords(Data_Wordlist):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        self.wordlist = previous.wordlist\n",
    "    \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        if not self.is_testing:\n",
    "            label_column = [\"label\"]\n",
    "\n",
    "        columns = label_column + list(\n",
    "            map(lambda w: w + \">\",self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if not self.is_testing:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"emotion\"]\n",
    "                labels.append(current_label)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"comment\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>merci&gt;</th>\n",
       "      <th>orang&gt;</th>\n",
       "      <th>و&gt;</th>\n",
       "      <th>في&gt;</th>\n",
       "      <th>w&gt;</th>\n",
       "      <th>de&gt;</th>\n",
       "      <th>le&gt;</th>\n",
       "      <th>من&gt;</th>\n",
       "      <th>dima&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>bonu&gt;</th>\n",
       "      <th>فلوس&gt;</th>\n",
       "      <th>forfait&gt;</th>\n",
       "      <th>lel&gt;</th>\n",
       "      <th>يكون&gt;</th>\n",
       "      <th>وكل&gt;</th>\n",
       "      <th>oredoo&gt;</th>\n",
       "      <th>ooredoo&gt;</th>\n",
       "      <th>wala&gt;</th>\n",
       "      <th>tunisi&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  merci>  orang>  و>  في>  w>  de>  le>  من>  dima>   ...     \\\n",
       "0  negative       0       0   0    0   0    0    0    0      0   ...      \n",
       "1  negative       0       0   1    0   0    0    0    1      0   ...      \n",
       "2  negative       0       1   0    0   0    0    1    0      0   ...      \n",
       "3  negative       0       1   0    0   0    0    0    0      1   ...      \n",
       "4  positive       0       1   0    0   0    0    0    0      0   ...      \n",
       "\n",
       "   bonu>  فلوس>  forfait>  lel>  يكون>  وكل>  oredoo>  ooredoo>  wala>  \\\n",
       "0      0      0         0     0      0     0        0         0      0   \n",
       "1      0      0         0     0      0     0        0         0      0   \n",
       "2      0      0         0     0      0     0        0         0      0   \n",
       "3      0      0         0     0      0     0        0         0      0   \n",
       "4      0      0         0     0      0     0        0         0      0   \n",
       "\n",
       "   tunisi>  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_BagOfWords(data)\n",
    "bow, labels = data.build_data_model()\n",
    "bow.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = bow.groupby([\"label\"]).sum()\n",
    "words_to_visualize = []\n",
    "sentiments = [\"positive\",\"negative\"]\n",
    "#get the most 7 common words for every sentiment\n",
    "for sentiment in sentiments:\n",
    "    words = grouped.loc[sentiment,:]\n",
    "    words.sort_values(inplace=True,ascending=False)\n",
    "    for w in words.index[:7]:\n",
    "        if w not in words_to_visualize:\n",
    "            words_to_visualize.append(w)\n",
    "            \n",
    "            \n",
    "#visualize it\n",
    "plot_data = []\n",
    "for sentiment in sentiments:\n",
    "    plot_data.append(graph_objs.Bar(\n",
    "            x = [w.split(\"_\")[0] for w in words_to_visualize],\n",
    "            y = [grouped.loc[sentiment,w] for w in words_to_visualize],\n",
    "            name = sentiment\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "py.tools.set_credentials_file(username='samirromdhani', api_key='ia0qpy717g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.tools as plotly_tools\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### First of all, lets establish seed for random numbers generators.\n",
    "import random\n",
    "seed = 666\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## BOW + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7:3 train:test\n",
    "#350 train , 150 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing BernoulliNB\n",
      "Learing time 0.005010366439819336s\n",
      "Predicting time 0.0010030269622802734s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [0.55813953 0.66666667]\n",
      "Precision[0.72 0.57]\n",
      "Recall   [0.4556962 0.8028169]\n",
      "Accuracy 0.62\n",
      "===============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=bow.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392    positive\n",
       "424    negative\n",
       "140    positive\n",
       "231    positive\n",
       "36     negative\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452    negative\n",
       "125    positive\n",
       "418    negative\n",
       "56     positive\n",
       "2      negative\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(classifier, X_train, y_train):\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    now = time()\n",
    "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
    "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
    "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
    "    log(\"Accuracy: \" + str(accuracy[0]))\n",
    "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
    "    log(\"===============================================\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating BernoulliNB...\n",
      "Crosvalidation completed in 5.642962217330933s\n",
      "Accuracy: [0.53968254 0.65079365 0.63492063 0.55555556 0.68253968 0.69354839\n",
      " 0.70491803 0.59016393]\n",
      "Average accuracy: 0.631515302225244\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "nb_acc = cv(BernoulliNB(), bow.iloc[:,1:], bow.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
