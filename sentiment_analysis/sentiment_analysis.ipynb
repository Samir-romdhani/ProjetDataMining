{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "\n",
    "# plotly configuration\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\",\"comment\", \"emotion\", \"date\",\"url\"])\n",
    "            self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\"])]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"comment\"],dtype={\"id\":\"int64\",\"text\":\"str\"},nrows=4000)\n",
    "            not_null_text = 1 ^ pd.isnull(self.data[\"comment\"])\n",
    "            not_null_id = 1 ^ pd.isnull(self.data[\"id\"])\n",
    "            self.data = self.data.loc[not_null_id & not_null_text, :]\n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange, pk l'connexion ,ma@ t7ebech temc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoum 3adet fourfi 900 ta3 7 jour ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>N7eb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment   emotion  \\\n",
       "0   0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1   1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2   2  brabi orange, pk l'connexion ,ma@ t7ebech temc...  negative   \n",
       "3   3  slm orange elyoum 3adet fourfi 900 ta3 7 jour ...  negative   \n",
       "4   4                                        N7eb orange  positive   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Initialize()\n",
    "data.initialize(\"data\\\\four-column500v1.4.csv\")\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.processed_data\n",
    "neg = len(df[df[\"emotion\"] == \"negative\"])\n",
    "pos = len(df[df[\"emotion\"] == \"positive\"])\n",
    "#neu = len(df[df[\"emotion\"] == \"neutral\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"negative\",\"positive\"],\n",
    "        y=[neg, pos],\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PostCleanuper:\n",
    "    def iterate(self):\n",
    "        for cleanup_method in [self.remove_urls,\n",
    "                               self.remove_usernames,\n",
    "                               self.remove_na,\n",
    "                               self.remove_special_chars,\n",
    "                               self.remove_numbers]:\n",
    "            yield cleanup_method\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_by_regex(tweets, regexp):\n",
    "        tweets.loc[:, \"comment\"].replace(regexp, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_urls(self, tweets):\n",
    "        return PostCleanuper.remove_by_regex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_na(self, tweets):\n",
    "        return tweets[tweets[\"comment\"] != \"Not Available\"]\n",
    "\n",
    "    def remove_special_chars(self, tweets):  # it unrolls the hashtags to normal words\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "            tweets.loc[:, \"comment\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_usernames(self, tweets):\n",
    "        return PostCleanuper.remove_by_regex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_numbers(self, tweets):\n",
    "        return PostCleanuper.remove_by_regex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Cleansing(Data_Initialize):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def cleanup(self, cleanuper):\n",
    "        t = self.processed_data\n",
    "        for cleanup_method in cleanuper.iterate():\n",
    "            if not self.is_testing:\n",
    "                t = cleanup_method(t)\n",
    "            else:\n",
    "                if cleanup_method.__name__ != \"remove_na\":\n",
    "                    t = cleanup_method(t)\n",
    "\n",
    "        self.processed_data = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange pk lconnexion ma tebech temchili ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoumadet fourfi ta jour tantli ma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Neb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment   emotion  \\\n",
       "0   0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1   1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2   2  brabi orange pk lconnexion ma tebech temchili ...  negative   \n",
       "3   3  slm orange elyoumadet fourfi ta jour tantli ma...  negative   \n",
       "4   4                                         Neb orange  positive   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Cleansing(data)\n",
    "data.cleanup(PostCleanuper())\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_TokenStem(Data_Cleansing):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"comment\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"comment\"]))\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"comment\"] = tokenizer(row[\"comment\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"comment\"]\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['في_بيتنا',\n",
       " 'كل',\n",
       " 'شي',\n",
       " 'لما',\n",
       " 'تحتاجه',\n",
       " 'يضيع',\n",
       " '...',\n",
       " 'ادور',\n",
       " 'على',\n",
       " 'شاحن',\n",
       " 'فجأة',\n",
       " 'يختفي']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize('في_بيتنا كل شي لما تحتاجه يضيع ...ادور على شاحن فجأة يختفي  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[brabi, orang, pk, lconnexion, ma, tebech, tem...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[brabi, orange, pk, lconnexion, ma, tebech, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[slm, orang, elyoumadet, fourfi, ta, jour, tan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[slm, orange, elyoumadet, fourfi, ta, jour, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[neb, orang]</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "      <td>[Neb, orange]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[حزين]</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-08T19:15:36+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "      <td>[حزين]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[نسالكم, ميغاا, الله, لا, تربحكم, انتم, باش, ت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:11:40+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[نسالكم, ميغاا, الله, لا, تربحكم, انتم, باش, ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[problèm, de, connexion, avec, le, site, inter...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-09T18:10:08+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155990...</td>\n",
       "      <td>[Problème, de, connexion, avec, les, sites, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[bon, orang, pk, la, connexion, tbch, temchi, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:47:32+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[bon, orange, pk, la, connexion, tbch, temchi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[aslma, orang, belhi, neb, nareflach, neetow, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T21:43:12+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "      <td>[aslma, orange, belhy, neb, nareflach, neetow,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            comment   emotion  \\\n",
       "0   0  [عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...  negative   \n",
       "1   1  [اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...  negative   \n",
       "2   2  [brabi, orang, pk, lconnexion, ma, tebech, tem...  negative   \n",
       "3   3  [slm, orang, elyoumadet, fourfi, ta, jour, tan...  negative   \n",
       "4   4                                       [neb, orang]  positive   \n",
       "5   5                                             [حزين]  negative   \n",
       "6   6  [نسالكم, ميغاا, الله, لا, تربحكم, انتم, باش, ت...  negative   \n",
       "7   7  [problèm, de, connexion, avec, le, site, inter...  negative   \n",
       "8   8  [bon, orang, pk, la, connexion, tbch, temchi, ...  negative   \n",
       "9   9  [aslma, orang, belhi, neb, nareflach, neetow, ...  negative   \n",
       "\n",
       "                       date  \\\n",
       "0  2018-01-02T19:16:17+0000   \n",
       "1  2018-01-02T19:43:48+0000   \n",
       "2  2018-01-02T20:37:47+0000   \n",
       "3  2018-01-02T19:00:49+0000   \n",
       "4  2018-01-08T20:13:49+0000   \n",
       "5  2018-01-08T19:15:36+0000   \n",
       "6  2018-01-02T19:11:40+0000   \n",
       "7  2018-01-09T18:10:08+0000   \n",
       "8  2018-01-02T20:47:32+0000   \n",
       "9  2018-01-02T21:43:12+0000   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.facebook.com/298166859034_10155976...   \n",
       "1  https://www.facebook.com/298166859034_10155976...   \n",
       "2  https://www.facebook.com/298166859034_10155976...   \n",
       "3  https://www.facebook.com/298166859034_10155976...   \n",
       "4  https://www.facebook.com/298166859034_10155991...   \n",
       "5  https://www.facebook.com/298166859034_10155991...   \n",
       "6  https://www.facebook.com/298166859034_10155976...   \n",
       "7  https://www.facebook.com/298166859034_10155990...   \n",
       "8  https://www.facebook.com/298166859034_10155976...   \n",
       "9  https://www.facebook.com/298166859034_10155976...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [عسلامة, أورونج, رقدت, مخلي, ال, puce, متاعي, ...  \n",
       "1  [اورونج, نحب, نقلكم, عيشكم, خاتر, انتوما, الوح...  \n",
       "2  [brabi, orange, pk, lconnexion, ma, tebech, te...  \n",
       "3  [slm, orange, elyoumadet, fourfi, ta, jour, ta...  \n",
       "4                                      [Neb, orange]  \n",
       "5                                             [حزين]  \n",
       "6  [نسالكم, ميغاا, الله, لا, تربحكم, انتم, باش, ت...  \n",
       "7  [Problème, de, connexion, avec, les, sites, in...  \n",
       "8  [bon, orange, pk, la, connexion, tbch, temchi,...  \n",
       "9  [aslma, orange, belhy, neb, nareflach, neetow,...  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_TokenStem(data)\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.processed_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\"Building the wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merci', 196), ('orang', 137), ('و', 72), ('في', 72), ('w', 63)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.index:\n",
    "    words.update(data.processed_data.loc[idx, \"comment\"])\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merci', 196), ('orang', 137), ('و', 72), ('في', 72), ('w', 63)]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Wordlist(Data_TokenStem):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    whitelist = [\"n't\",\"not\"]\n",
    "    wordlist = []\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=3, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        import os\n",
    "        if os.path.isfile(\"data\\\\wordlistv1.5.csv\"):\n",
    "            word_df = pd.read_csv(\"data\\\\wordlistv1.5.csv\",encoding=\"utf-8\")\n",
    "            word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "            self.wordlist = list(word_df.loc[:, \"word\"])\n",
    "            return\n",
    "\n",
    "        words = Counter()\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"comment\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"data\\\\wordlistv1.5.csv\", index_label=\"idx\" ,encoding=\"utf-8\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Wordlist(data)\n",
    "data.build_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"data\\\\wordlistv1.5.csv\", encoding=\"utf-8\")\n",
    "x_words = list(words.loc[0:10,\"word\"])\n",
    "x_words.reverse()\n",
    "y_occ = list(words.loc[0:10,\"occurrences\"])\n",
    "y_occ.reverse()\n",
    "\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=y_occ,\n",
    "        y=x_words,\n",
    "        orientation=\"h\"\n",
    ")]\n",
    "#plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Top words in built wordlist\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import codecs\n",
    "#with codecs.open(\"data\\\\wordlistv1.4.csv\", \"r\",encoding='utf-8', errors='ignore') as fdata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(\"data\\\\wordlist.csv\", encoding=\"latin-1\") as datafile:\n",
    "#words = pd.read_csv(\"data\\\\wordlistv1.4.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 11 artists>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2292f7fbb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x_words,y_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_BagOfWords(Data_Wordlist):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        self.wordlist = previous.wordlist\n",
    "    \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        if not self.is_testing:\n",
    "            label_column = [\"label\"]\n",
    "\n",
    "        columns = label_column + list(\n",
    "            map(lambda w: w + \">\",self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if not self.is_testing:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"emotion\"]\n",
    "                labels.append(current_label)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"comment\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>merci&gt;</th>\n",
       "      <th>orang&gt;</th>\n",
       "      <th>و&gt;</th>\n",
       "      <th>في&gt;</th>\n",
       "      <th>w&gt;</th>\n",
       "      <th>de&gt;</th>\n",
       "      <th>le&gt;</th>\n",
       "      <th>من&gt;</th>\n",
       "      <th>dima&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>bonu&gt;</th>\n",
       "      <th>فلوس&gt;</th>\n",
       "      <th>forfait&gt;</th>\n",
       "      <th>lel&gt;</th>\n",
       "      <th>يكون&gt;</th>\n",
       "      <th>وكل&gt;</th>\n",
       "      <th>oredoo&gt;</th>\n",
       "      <th>ooredoo&gt;</th>\n",
       "      <th>wala&gt;</th>\n",
       "      <th>tunisi&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  merci>  orang>  و>  في>  w>  de>  le>  من>  dima>   ...     \\\n",
       "0  negative       0       0   0    0   0    0    0    0      0   ...      \n",
       "1  negative       0       0   1    0   0    0    0    1      0   ...      \n",
       "2  negative       0       1   0    0   0    0    1    0      0   ...      \n",
       "3  negative       0       1   0    0   0    0    0    0      1   ...      \n",
       "4  positive       0       1   0    0   0    0    0    0      0   ...      \n",
       "\n",
       "   bonu>  فلوس>  forfait>  lel>  يكون>  وكل>  oredoo>  ooredoo>  wala>  \\\n",
       "0      0      0         0     0      0     0        0         0      0   \n",
       "1      0      0         0     0      0     0        0         0      0   \n",
       "2      0      0         0     0      0     0        0         0      0   \n",
       "3      0      0         0     0      0     0        0         0      0   \n",
       "4      0      0         0     0      0     0        0         0      0   \n",
       "\n",
       "   tunisi>  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_BagOfWords(data)\n",
    "bow, labels = data.build_data_model()\n",
    "bow.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly as py\n",
    "py.tools.set_credentials_file(username='samirromdhani', api_key='IF3CeJTO4T6KKPrW2KRc')\n",
    "init_notebook_mode(connected=True)\n",
    "from plotly.graph_objs import Scatter, Figure, Layout\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = bow.groupby([\"label\"]).sum()\n",
    "words_to_visualize = []\n",
    "sentiments = [\"positive\",\"negative\"]\n",
    "#get the most 7 common words for every sentiment\n",
    "for sentiment in sentiments:\n",
    "    words = grouped.loc[sentiment,:]\n",
    "    words.sort_values(inplace=True,ascending=False)\n",
    "    for w in words.index[:15]:\n",
    "        if w not in words_to_visualize:\n",
    "            words_to_visualize.append(w)\n",
    "            \n",
    "            \n",
    "#visualize it\n",
    "plot_data = []\n",
    "for sentiment in sentiments:\n",
    "    plot_data.append(graph_objs.Bar(\n",
    "            x = [w.split(\"_\")[0] for w in words_to_visualize],\n",
    "            y = [grouped.loc[sentiment,w] for w in words_to_visualize],\n",
    "            name = sentiment\n",
    "    ))\n",
    "len(words_to_visualize)\n",
    "#words_to_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\user\\\\Desktop\\\\Ensi-II3-ISID\\\\sem2\\\\datamining\\\\projets\\\\git my project\\\\ProjetDataMining\\\\sentiment_analysis\\\\temp-plot.html'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "offline.plot({'data': plot_data, \n",
    "               'layout': graph_objs.Layout(title=\"Most common words across sentiments\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot([Scatter(x=[1, 2, 3], y=[3, 1, 6])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### First of all, lets establish seed for random numbers generators.\n",
    "import random\n",
    "seed = 666\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## BOW + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7:3 train:test\n",
    "#350 train , 150 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing BernoulliNB\n",
      "Learing time 0.08921289443969727s\n",
      "Predicting time 0.016045570373535156s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [0.55813953 0.66666667]\n",
      "Precision[0.72 0.57]\n",
      "Recall   [0.4556962 0.8028169]\n",
      "Accuracy 0.62\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=bow.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392    positive\n",
       "424    negative\n",
       "140    positive\n",
       "231    positive\n",
       "36     negative\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452    negative\n",
       "125    positive\n",
       "418    negative\n",
       "56     positive\n",
       "2      negative\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(classifier, X_train, y_train):\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    now = time()\n",
    "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
    "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
    "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
    "    log(\"Accuracy: \" + str(accuracy[0]))\n",
    "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
    "    log(\"===============================================\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating BernoulliNB...\n",
      "Crosvalidation completed in 19.27809166908264s\n",
      "Accuracy: [0.53968254 0.65079365 0.63492063 0.55555556 0.68253968 0.69354839\n",
      " 0.70491803 0.59016393]\n",
      "Average accuracy: 0.631515302225244\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "nb_acc = cv(BernoulliNB(), bow.iloc[:,1:], bow.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
