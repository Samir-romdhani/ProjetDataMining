{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plotly configuration\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"idx\",\"comment\", \"emotion\", \"date\",\"url\"])\n",
    "            self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\"])]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"comment\"],dtype={\"comment\":\"str\"},nrows=4000)\n",
    "            not_null_text = 1 ^ pd.isnull(self.data[\"comment\"])\n",
    "            not_null_id = 1 ^ pd.isnull(self.data[\"idx\"])\n",
    "            self.data = self.data.loc[not_null_id & not_null_text, :]\n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange, pk l'connexion ,ma@ t7ebech temc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoum 3adet fourfi 900 ta3 7 jour ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>N7eb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>حزين</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-08T19:15:36+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>نسالكم 70 ميغاا الله لا تربحكم انتم باش تربحوو...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:11:40+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Problème de connexion avec les sites internati...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-09T18:10:08+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>bon orange pk la connexion t7bch temchi ken fa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:47:32+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3aslma orange belhy n7eb na3ref 3lach ne7etow ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T21:43:12+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            comment   emotion  \\\n",
       "0    0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1    1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2    2  brabi orange, pk l'connexion ,ma@ t7ebech temc...  negative   \n",
       "3    3  slm orange elyoum 3adet fourfi 900 ta3 7 jour ...  negative   \n",
       "4    4                                        N7eb orange  positive   \n",
       "5    5                                               حزين  negative   \n",
       "6    6  نسالكم 70 ميغاا الله لا تربحكم انتم باش تربحوو...  negative   \n",
       "7    7  Problème de connexion avec les sites internati...  negative   \n",
       "8    8  bon orange pk la connexion t7bch temchi ken fa...  negative   \n",
       "9    9  3aslma orange belhy n7eb na3ref 3lach ne7etow ...  negative   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  \n",
       "5  2018-01-08T19:15:36+0000  https://www.facebook.com/298166859034_10155991...  \n",
       "6  2018-01-02T19:11:40+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "7  2018-01-09T18:10:08+0000  https://www.facebook.com/298166859034_10155990...  \n",
       "8  2018-01-02T20:47:32+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "9  2018-01-02T21:43:12+0000  https://www.facebook.com/298166859034_10155976...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Initialize()\n",
    "data.initialize(\"data\\\\four-column500v1.2.csv\")\n",
    "data.processed_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.processed_data\n",
    "neg = len(df[df[\"emotion\"] == \"negative\"])\n",
    "pos = len(df[df[\"emotion\"] == \"positive\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"negative\",\"positive\"],\n",
    "        y=[neg, pos],\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "negative    262\n",
       "positive    237\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupEmotion = df.groupby('emotion').size()\n",
    "print(type(groupEmotion))\n",
    "groupEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 2 artists>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26de20dfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(groupEmotion.index, groupEmotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عسلامة\n",
      "أورونج\n",
      "رقدت\n",
      "مخلي\n",
      "ال\n",
      "puce\n",
      "متاعي\n",
      "أورونج\n",
      "قمت\n",
      "نلقاها\n",
      "تبدلت\n",
      "أوريدو\n",
      "بلاهي\n",
      "كيفاش\n",
      "نبدلها\n",
      "تليكوم\n",
      "اورونج\n",
      "نحب\n",
      "نقلكم\n",
      "عيشكم\n",
      "خاتر\n",
      "انتوما\n",
      "الوحدين\n",
      "تتفكروني\n",
      "تعيدو\n",
      "عليا\n",
      "قبل\n",
      "عيلتي\n",
      "و\n",
      "مبعد\n",
      "تبعثولي\n",
      "ميساج\n",
      "تقولولي\n",
      "راهو\n",
      "فلوسك\n",
      "وفاو\n",
      "تعرف\n",
      "الي\n",
      "انا\n",
      "مبارح\n",
      "صبيت\n",
      "دينار\n",
      "ياخي\n",
      "سرقتوه\n",
      "تعرفووووو...😠😠\n",
      "مصح\n",
      "الرقعة\n",
      "😑\n",
      "كان\n",
      "جيت\n",
      "انجم\n",
      "نقتل\n",
      "واحد\n",
      "راني\n",
      "مشيت\n",
      "طول\n",
      "انلوج\n",
      "الي\n",
      "يبعثلي\n",
      "مساج\n",
      "يقلي\n",
      "فيه\n",
      "راهو\n",
      "فلوسك\n",
      "وفاو😈\n",
      "و\n",
      "شكرا\n",
      ".....\n",
      "من\n",
      "دون\n",
      "تصفيق\n",
      "😂😂\n",
      "brabi\n",
      "orange,\n",
      "pk\n",
      "l'connexion\n",
      ",ma@\n",
      "t7ebech\n",
      "temchili\n",
      "kan\n",
      "fcbk\n",
      "7ata\n",
      "le\n",
      "messenger\n",
      "ma\n",
      "najemtech\n",
      "na3mlelha\n",
      "téléchargement\n",
      "en\n",
      "plus\n",
      "le\n",
      "play\n",
      "store\n",
      "ma\n",
      "7abech\n",
      "chniya\n",
      "ilmochkla\n",
      "brabi\n",
      "slm\n",
      "orange\n",
      "elyoum\n",
      "3adet\n",
      "fourfi\n",
      "900\n",
      "ta3\n",
      "7\n",
      "jour\n",
      "tan7tli\n",
      "1800\n",
      "maya\n",
      "a3lech\n",
      "na7touhem\n",
      "dima\n",
      "tasrli\n",
      "hadi\n",
      "N7eb\n",
      "orange\n",
      "حزين\n",
      "نسالكم\n",
      "70\n",
      "ميغاا\n",
      "الله\n",
      "لا\n",
      "تربحكم\n",
      "انتم\n",
      "باش\n",
      "تربحوو\n",
      "الشعب\n",
      "يا\n",
      "متحيلين\n",
      "ان\n",
      "شاء\n",
      "الله\n",
      "70\n",
      "ميغاا\n",
      "تطلعلكم\n",
      "70\n",
      "مليار\n",
      "خسارة\n",
      "Problème\n",
      "de\n",
      "connexion\n",
      "avec\n",
      "les\n",
      "sites\n",
      "internationaux\n",
      "en\n",
      "4G\n",
      "!!!\n",
      "echnouwa\n",
      "hedha!\n",
      "echnouwa\n",
      "ye5i\n",
      "Facebook,\n",
      "Youtube\n",
      ",\n",
      "twitter\n",
      "welbe9i\n",
      "ma3andenech\n",
      "el7a9??!!\n",
      "bon\n",
      "orange\n",
      "pk\n",
      "la\n",
      "connexion\n",
      "t7bch\n",
      "temchi\n",
      "ken\n",
      "facebook\n",
      "ama\n",
      "youtube\n",
      "t7ebech😤😤😲\n",
      "plzzz\n",
      "gedou\n",
      "connexion\n",
      "c'est\n",
      "rien\n",
      "ok🤗🤗\n",
      "3aslma\n",
      "orange\n",
      "belhy\n",
      "n7eb\n",
      "na3ref\n",
      "3lach\n",
      "ne7etow\n",
      "barcha\n",
      "7ajet\n",
      "kanow\n",
      "mawjodin\n",
      "fel\n",
      "offert\n",
      "d'appelle\n",
      "any\n",
      "wa7da\n",
      "mens\n",
      "5alwony\n",
      "nkon\n",
      "men\n",
      "7ourfkom\n",
      "wtaw\n",
      "bsar7a\n",
      "walit\n",
      "nlawej\n",
      "3lla\n",
      "ay\n",
      "5admt\n",
      "o5ra\n",
      "tsa3edny\n",
      "احساسنا\n",
      "الي\n",
      "كثروتولها\n",
      "مالسارقة\n",
      "في\n",
      "الانترنات\n",
      "ركم\n",
      "مرجتونا\n",
      "و\n",
      "مصلحة\n",
      "الحرفاء\n",
      "كي\n",
      "بيها\n",
      "كي\n",
      "بلاش\n",
      "ana\n",
      "3andi\n",
      "el\n",
      "orange\n",
      "wel\n",
      "telekom\n",
      "00000\n",
      "ok\n",
      "a3azhom\n",
      "tunisiana\n",
      "tay7et\n",
      "3likom\n",
      "rabi\n",
      "m3aha\n",
      "..\n",
      "Ya5i\n",
      "chnia\n",
      "la7ya\n",
      "ser9a\n",
      "3ini\n",
      "3ink\n",
      "3mlt\n",
      "abonement\n",
      "b\n",
      "1\n",
      "mois\n",
      "750m\n",
      "7atit\n",
      "carte\n",
      "b\n",
      "5\n",
      "d\n",
      "nrml\n",
      "tnt7l\n",
      "3\n",
      "d\n",
      "w\n",
      "ra8m\n",
      "hatha\n",
      "w\n",
      "3ml\n",
      "abonment\n",
      "lflos\n",
      "9a3ad\n",
      "tn9osli\n",
      "ya5i\n",
      "chnwa\n",
      "hatha\n",
      "ytsma????\n",
      "ارونح\n",
      "مرسسي\n",
      "علخر\n",
      "علخر\n",
      "والله\n",
      "💗💗💗💗💖💖💖\n",
      "خاطر\n",
      "بلحق\n",
      "ما\n",
      "يتفكرني\n",
      "حد\n",
      "كان\n",
      "انتي\n",
      "و\n",
      "كونكسيون\n",
      "متاعك\n",
      "عسل\n",
      "تشدلي\n",
      "ب3\n",
      "جمعات\n",
      "واهم\n",
      "حاجه\n",
      "انو\n",
      "كي\n",
      "يطلبني\n",
      "شكون\n",
      "ميفيقاش\n",
      "بيا\n",
      "كنت\n",
      "نحكي\n",
      "لا\n",
      "تجيه\n",
      "اوكيبي\n",
      "ولا\n",
      "ان\n",
      "اتونت\n",
      ":*\n",
      ":*\n",
      "ربي\n",
      "يخليكم\n",
      "اما\n",
      "بلاهي\n",
      "نقصو\n",
      "شوي\n",
      "من\n",
      "ميساجات\n",
      "متاع\n",
      "مساطه\n",
      "هو\n",
      "انتخابات\n",
      "هو\n",
      "عيد\n",
      "شجره\n",
      "هو\n",
      "استقلال\n",
      "اما\n",
      "بلاهي\n",
      "لا\n",
      "تنساني\n",
      "في\n",
      "عيد\n",
      "لحب\n",
      ":*\n",
      "إو\n",
      "جبتها\n",
      "وجيت\n",
      "بجاه\n",
      "ربي\n",
      "علاش\n",
      "السرقة\n",
      "ديما\n",
      "تعملولي\n",
      "فيها\n",
      "نصب\n",
      "كارتة\n",
      "ومن\n",
      "بعد\n",
      "تبدا\n",
      "تسرقولي\n",
      "منها\n",
      "لين\n",
      "توفا\n",
      "من\n",
      "غير\n",
      "منعمل\n",
      "بيها\n",
      "شي\n",
      "تبعثولي\n",
      "ميساجات\n",
      "وتهزو\n",
      "حقها\n",
      "من\n",
      "عندي\n",
      "علاش\n",
      "ومنحبش\n",
      "نعمل\n",
      "توناليتي\n",
      "تعملوهالي\n",
      "بالسيف\n",
      "ومنحبش\n",
      "العاب\n",
      "تعملولي\n",
      "اكسابت\n",
      "منغير\n",
      "منوافق\n",
      "افزح\n",
      "ربي\n",
      "يهديك\n",
      "يا\n",
      "اورونج\n",
      "بلهي\n",
      "بش\n",
      "نسلك\n",
      "كي\n",
      "يبد\n",
      "لواحد\n",
      "يتذضلم\n",
      "فلبوتيك\n",
      "كيفاش\n",
      "يخو\n",
      "حقو\n",
      "كاذبين\n",
      "ديما\n",
      "نشارك\n",
      "و\n",
      "شئ\n",
      "تربحو\n",
      "بالمعارف\n",
      "بالله\n",
      "عليكم\n",
      "اعملو\n",
      "حل\n",
      "فديت\n",
      "منكم\n",
      "4\n",
      "فايسبوك\n",
      "تأكل\n",
      "اكثر\n",
      "من\n",
      "1G\n",
      "وهذا\n",
      "لكل\n",
      "نستعمل\n",
      "في\n",
      "البيس\n",
      "متاعي\n",
      "شهر\n",
      "لفات\n",
      "10\n",
      "G\n",
      "في\n",
      "10\n",
      "ايام\n",
      "Yeser\n",
      "tsr9ou\n",
      "1G\n",
      "matchedch\n",
      "hâta\n",
      "jem3a\n",
      "كان\n",
      "كذب\n",
      "فيكم\n",
      "يااورنج\n",
      "زعم\n",
      "زعم\n",
      "تحب\n",
      "تفرهدون\n",
      "وتفرحون\n",
      "ونهار\n",
      "الكل\n",
      "تبعثولون\n",
      "في\n",
      "الميسجات\n",
      "علاش\n",
      "تكذبوا\n",
      "قولوا\n",
      "الحقيقةد\n",
      "wel\n",
      "sirka\n",
      "3ini\n",
      "3inik\n",
      "chnowa\n",
      "namlo\n",
      "feha\n",
      "!??\n",
      "مع\n",
      "أرونج\n",
      "الربح\n",
      "ممنوع\n",
      "servickom\n",
      "ka3ba\n",
      "la\n",
      "f\n",
      "aindraham,connexion\n",
      "dima\n",
      "tay7a.ana\n",
      "w\n",
      "3ayelti\n",
      "w\n",
      "as7abi\n",
      "5dhina\n",
      "decision\n",
      "bech\n",
      "nbadlou\n",
      "un\n",
      "autre\n",
      "operateur\n",
      "7asnou\n",
      "service\n",
      "w\n",
      "sayeb\n",
      "3likom\n",
      "mel\n",
      "koura,matefehmouhach.e5dmou\n",
      "5edmtk\n",
      "3ychkm,lahna\n",
      "f\n",
      "aindraham\n",
      "connexion\n",
      "7moum,dima\n",
      "tay7a\n",
      "اورونج\n",
      "العار\n",
      "بالرسمي...كونيكسيون\n",
      "تعيف\n",
      "معدل\n",
      "القصان\n",
      "في\n",
      "النهار\n",
      "450\n",
      "مرة\n",
      "و\n",
      "كي\n",
      "تكلم\n",
      "السرفيس\n",
      "تكنيك\n",
      "يبعثوك\n",
      "تقضي\n",
      "و\n",
      "كل\n",
      "واحد\n",
      "يعطيك\n",
      "كلام..فريمون\n",
      "الواحد\n",
      "يشوف\n",
      "فورنيسار\n",
      "اخر\n",
      "خير\n",
      "خاطر\n",
      "العباد\n",
      "تخلص\n",
      "في\n",
      "الكونيكسيون\n",
      "و\n",
      "انا\n",
      "نخلص\n",
      "في\n",
      "الكوبير\n",
      "Bonsoir,\n",
      "j'ai\n",
      "transformé\n",
      "des\n",
      "points\n",
      "cadeaux(800)\n",
      "vers\n",
      "500\n",
      "mo\n",
      "internet,\n",
      "mais\n",
      "le\n",
      "code\n",
      "qui\n",
      "m'a\n",
      "apparait\n",
      "pour\n",
      "consulter\n",
      "mon\n",
      "solde\n",
      "internet\n",
      "c'est\n",
      "*101*12#,\n",
      "mais\n",
      "il\n",
      "n'est\n",
      "pas\n",
      "valide\n",
      "pour\n",
      "cette\n",
      "opération.\n",
      "علامة\n",
      "أورنج\n",
      "أخي\n",
      "بدلتلي\n",
      "البيس\n",
      "أوريدو\n",
      "يا\n",
      "خي\n",
      "كي\n",
      "حليتها\n",
      "لقيتها\n",
      "هورنج\n",
      "مافهمت\n",
      "شيء\n",
      "orange\n",
      "rebhet\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "Orange\n",
      "😍❤❤\n",
      "Orange\n",
      "rebhet\n",
      "rakom\n",
      "kathertoulha\n",
      "bi\n",
      "sir9a\n",
      "jme3it\n",
      "orange\n",
      "merci.orange\n",
      "Ok\n",
      "👍👍\n",
      "Fatiguée\n",
      "😑\n",
      "Chbi\n",
      "waldikom\n",
      "orange?!!!\n",
      "La\n",
      "nhar\n",
      "taamlo\n",
      "haja\n",
      "tenfaa3!\n",
      "bonne\n",
      "année\n",
      "orange\n",
      "كل\n",
      "عام\n",
      "وانت\n",
      "بخير\n",
      "اورنج\n",
      "وخيتي\n",
      "راكي\n",
      "مرضتني\n",
      "ربح\n",
      "بالوجوه\n",
      "يزي\n",
      "من\n",
      "كذيب\n",
      "magnifique\n",
      "a\n",
      "quel\n",
      "prix\n",
      "الغلي\n",
      "و\n",
      "الكوي\n",
      "bonne\n",
      "année\n",
      "orange\n",
      "j\n",
      "espere\n",
      "que\n",
      "votre\n",
      "service\n",
      "technique\n",
      "s\n",
      "améliore\n",
      "c\n",
      "catastrophique\n",
      "j\n",
      "ai\n",
      "l\n",
      "adsl\n",
      "le\n",
      "réseau\n",
      "à\n",
      "97\n",
      "pour\n",
      "cent\n",
      "est\n",
      "zéro\n",
      "tout\n",
      "le\n",
      "temps\n",
      "je\n",
      "réclame\n",
      "enfin\n",
      "aeiiiiittttttt\n",
      "bonne\n",
      "annee\n",
      "orange\n",
      "ena\n",
      "3andi\n",
      "05\n",
      "pus\n",
      "w\n",
      "dima\n",
      "nal3ab\n",
      "m3akom\n",
      "w\n",
      "ma3labelich\n",
      "nerbeh\n",
      "wella\n",
      "lee\n",
      "vive\n",
      "orange\n",
      "انا\n",
      "تعجبني\n",
      "اورنج\n",
      "عندي\n",
      "زوز\n",
      "بيسات\n",
      "ويعجبني\n",
      "فيها\n",
      "الانترنات\n",
      "سريعة\n",
      "لكن\n",
      "عمري\n",
      "ماربحت\n",
      "في\n",
      "حتى\n",
      "مسابقة\n",
      "في\n",
      "حياتي\n",
      "انشاء\n",
      "الله\n",
      "تصدف\n",
      "في\n",
      "2018،bonne\n",
      "annee\n",
      "orange\n",
      "انا\n",
      "تعجبني\n",
      "اورنج\n",
      "عندي\n",
      "زوز\n",
      "بيسات\n",
      "ويعجبني\n",
      "فيها\n",
      "الانترنات\n",
      "سريعة\n",
      "لكن\n",
      "عمري\n",
      "ماربحت\n",
      "في\n",
      "حتى\n",
      "مسابقة\n",
      "في\n",
      "حياتي\n",
      "انشاء\n",
      "الله\n",
      "تصدف\n",
      "في\n",
      "2018،bonne\n",
      "annee\n",
      "orange\n",
      "nchala\n",
      "3amkom\n",
      "mabrouke\n",
      "orange\n",
      "nchala\n",
      "trabhona\n",
      "fi\n",
      "haja\n",
      "we\n",
      "nchala\n",
      "dima\n",
      "farhanin\n",
      "we\n",
      "tishale\n",
      "oumore\n",
      "انا\n",
      "تعجبني\n",
      "اورنج\n",
      "عندي\n",
      "زوز\n",
      "بيسات\n",
      "ويعجبني\n",
      "فيها\n",
      "الانترنات\n",
      "سريعة\n",
      "لكن\n",
      "عمري\n",
      "ماربحت\n",
      "في\n",
      "حتى\n",
      "مسابقة\n",
      "في\n",
      "حياتي\n",
      "انشاء\n",
      "الله\n",
      "تصدف\n",
      "في\n",
      "2018،bonne\n",
      "annee\n",
      "orange\n",
      "3malt\n",
      "m3akom\n",
      "jaw\n",
      "3alami\n",
      "nahitouli\n",
      "flousi\n",
      "kima\n",
      "habitou\n",
      "w\n",
      "chthitou\n",
      "kol\n",
      "chhar\n",
      "w\n",
      "ana\n",
      "nejri\n",
      "n5ales\n",
      "fel\n",
      "flybox\n",
      "احلئ\n",
      "جو\n",
      "تعدئ\n",
      "مع\n",
      "اورنج\n",
      "هو\n",
      "عام\n",
      "سنا\n",
      "ربحت\n",
      "فيه\n",
      "انترنات\n",
      "ربحت\n",
      "فيه\n",
      "بطاقة\n",
      "شحن\n",
      "هاتف\n",
      "وربحت\n",
      "فيه\n",
      "تليفون\n",
      "من\n",
      "نوع\n",
      "رفيع\n",
      "مرسي\n",
      "اورنج\n",
      "انشالله\n",
      "ديما\n",
      "منورين\n",
      "والمزيد\n",
      "من\n",
      "تالق\n",
      "والعمل\n",
      "اورنج\n",
      "يمهبلتنا\n",
      "بافرياتك\n",
      "3amalt\n",
      "barcha\n",
      "jaw\n",
      "m3akoum\n",
      "3am\n",
      "2017\n",
      "winchallah\n",
      "n3awdou\n",
      "3am\n",
      "2018\n",
      "m3a\n",
      "les\n",
      "cadeaux\n",
      "mte3koum\n",
      "dima\n",
      "namele\n",
      "lé\n",
      "commontaire\n",
      "fel\n",
      "les\n",
      "jeux\n",
      "lkoule\n",
      "ou\n",
      "manthasele\n",
      "ala\n",
      "chaye\n",
      "am\n",
      "tokadou\n",
      "dima\n",
      "behine💕💜\n",
      "tii\n",
      "mnin\n",
      "brabi\n",
      "jaw\n",
      "dima\n",
      "nal3eb\n",
      "m3ekom\n",
      "w\n",
      "jamais\n",
      "rbe7et\n",
      "mnkom\n",
      "7eja\n",
      "bera8em\n",
      "3andi\n",
      "2\n",
      "pus\n",
      "orange\n",
      "w\n",
      "airbox\n",
      "ma3neha\n",
      "client\n",
      "w\n",
      "chy\n",
      "اورونج\n",
      "إن\n",
      "شاء\n",
      "الله\n",
      "كل\n",
      "عام\n",
      "وانت\n",
      "بخير\n",
      "وتكون\n",
      "متألقة\n",
      "دائما\n",
      "adsl\n",
      "mta3kom\n",
      "nja7\n",
      "hugh...salaktouha\n",
      "متعاقدين\n",
      "معاكم\n",
      "من\n",
      "عامين\n",
      "ونتمنى\n",
      "نربح\n",
      "حتى\n",
      "تلفون\n",
      "هههههههه\n",
      "في\n",
      "العام\n",
      "الجدي\n",
      "ra8mli\n",
      "marb7t\n",
      "me3akom\n",
      "hata\n",
      "chay\n",
      "ama\n",
      "bravo\n",
      "5ir\n",
      "men\n",
      "barcha\n",
      "t9oulou\n",
      "taw\n",
      "terb7ou\n",
      "w\n",
      "mathamma\n",
      "shay😒😒\n",
      "bonne\n",
      "année\n",
      "orange,\n",
      "beaucoup\n",
      "de\n",
      "réussite\n",
      "...\n",
      "3amelt\n",
      "ma3koum\n",
      "a7la\n",
      "jaw\n",
      "nachah\n",
      "3amkoum\n",
      "mabrouk\n",
      "orange\n",
      "Problème\n",
      "de\n",
      "connexion\n",
      "avec\n",
      "les\n",
      "sites\n",
      "internationaux\n",
      "en\n",
      "4G\n",
      "!!!\n",
      "echnouwa\n",
      "hedha!\n",
      "echnouwa\n",
      "ye5i\n",
      "Facebook,\n",
      "Youtube\n",
      ",\n",
      "twitter\n",
      "welbe9i\n",
      "ma3andenech\n",
      "el7a9??!!\n",
      "حسبنا\n",
      "الله\n",
      "ونعم\n",
      "الوكيل\n",
      "في\n",
      "الزيادات\n",
      "اعطوه\n",
      "على\n",
      "راسوا\n",
      "التونسي\n",
      "راهو\n",
      "مازال\n",
      "يتحمل\n",
      "Normalement\n",
      "Orange\n",
      "ntouma\n",
      "hakeka\n",
      "tetsarfou\n",
      "m3ana\n",
      "fel\n",
      "les\n",
      "services\n",
      "el\n",
      "7moum\n",
      "mte3kom\n",
      "بجاه\n",
      "ربي\n",
      "علاش\n",
      "السرقة\n",
      "ديما\n",
      "تعملولي\n",
      "فيها\n",
      "نصب\n",
      "كارتة\n",
      "ومن\n",
      "بعد\n",
      "تبدا\n",
      "تسرقولي\n",
      "منها\n",
      "لين\n",
      "توفا\n",
      "من\n",
      "غير\n",
      "منعمل\n",
      "بيها\n",
      "شي\n",
      "تبعثولي\n",
      "ميساجات\n",
      "وتهزو\n",
      "حقها\n",
      "من\n",
      "عندي\n",
      "علاش\n",
      "ومنحبش\n",
      "نعمل\n",
      "توناليتي\n",
      "تعملوهالي\n",
      "بالسيف\n",
      "ومنحبش\n",
      "العاب\n",
      "تعملولي\n",
      "اكسابت\n",
      "منغير\n",
      "منوافق\n",
      "افزح\n",
      "ربي\n",
      "يهديك\n",
      "يا\n",
      "اورونج\n",
      "ماعناش\n",
      "الحق\n",
      "في\n",
      "الربح\n",
      "والله\n",
      "العظيم\n",
      "تعطيو\n",
      "في\n",
      "الكادوات\n",
      "بالوجوه\n",
      "صحة\n",
      "ليكم\n",
      "واحنا\n",
      "منربحوش\n",
      "حتى\n",
      "شي\n",
      "عله\n",
      "اقسم\n",
      "بأنني\n",
      "اوال\n",
      "انسان\n",
      "سوف\n",
      "يقاطع\n",
      "الكونكسيون\n",
      "على\n",
      "الزيادات\n",
      "والاستكراش\n",
      "على\n",
      "الشعب\n",
      "المسكين\n",
      "نعلبوا\n",
      "الكونكسيون\n",
      "على\n",
      "فكرة\n",
      "اسألوا\n",
      "اورنج\n",
      "قداش\n",
      "نستهلك\n",
      "بخلاف\n",
      "اولادي\n",
      "هالبلاد\n",
      "مشات\n",
      "في\n",
      "هاوية\n",
      "الزيادات\n",
      "اقسم\n",
      "او\n",
      "فرصة\n",
      "في\n",
      "الهجرة\n",
      "سوف\n",
      "ارحل\n",
      "نعل................\n",
      "Triste\n",
      "car\n",
      "j'ai\n",
      "pas\n",
      "gainer\n",
      "aucune\n",
      "chose\n",
      "avec\n",
      "Orange\n",
      "malgré\n",
      "que\n",
      "je\n",
      "suis\n",
      "client\n",
      "fidèle\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-e4d7899d608a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(word)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-e4d7899d608a>\u001b[0m in \u001b[0;36mwords\u001b[1;34m(stringIterable)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlineStream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstringIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlineStream\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#enumerate the lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#further break them down\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "#Every word is converted into a feature using a simplified bag of words model:\n",
    "def words(stringIterable):\n",
    "    lineStream = iter(stringIterable)\n",
    "    for line in lineStream: #enumerate the lines\n",
    "        for word in line.split(): #further break them down\n",
    "            yield word\n",
    "\n",
    "listepos = []\n",
    "listeneg = []\n",
    "for word in data.processed_data.comment:\n",
    "    #print(word)\n",
    "    for w in words([word]):\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_TokenStem(TwitterData_Cleansing):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"comment\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"comment\"]))\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"comment\"] = tokenizer(row[\"comment\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"comment\"]\n",
    "            return row\n",
    "    def custom_tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            if not row[\"comment\"]:\n",
    "                print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "                row[\"comment\"] = ''\n",
    "                return row\n",
    "            df['tokenized_column'] = df.column.apply(custom_tokenize)\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TwitterData_TokenStem(data)\n",
    "#data.custom_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange pk lconnexion ma tebech temchili ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoumadet fourfi ta jour tantli ma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Neb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            comment   emotion  \\\n",
       "0    0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1    1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2    2  brabi orange pk lconnexion ma tebech temchili ...  negative   \n",
       "3    3  slm orange elyoumadet fourfi ta jour tantli ma...  negative   \n",
       "4    4                                         Neb orange  positive   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_TokenStem(data)\n",
    "#data.tokenize()\n",
    "#data.stem()\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-71b05b9426f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"comment\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fast path when counter is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0m_count_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.index:\n",
    "    words.update(data.processed_data.loc[idx, \"comment\"])\n",
    "\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterCleanuper:\n",
    "    def iterate(self):\n",
    "        for cleanup_method in [self.remove_urls,\n",
    "                               self.remove_usernames,\n",
    "                               self.remove_na,\n",
    "                               self.remove_special_chars,\n",
    "                               self.remove_numbers]:\n",
    "            yield cleanup_method\n",
    "    @staticmethod\n",
    "    def remove_by_regex(tweets, regexp):\n",
    "        tweets.loc[:, \"comment\"].replace(regexp, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_urls(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_na(self, tweets):\n",
    "        return tweets[tweets[\"comment\"] != \"Not Available\"]\n",
    "\n",
    "    def remove_special_chars(self, tweets):  # it unrolls the hashtags to normal words\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "            tweets.loc[:, \"comment\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_usernames(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_numbers(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Cleansing(Data_Initialize):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def cleanup(self, cleanuper):\n",
    "        t = self.processed_data\n",
    "        for cleanup_method in cleanuper.iterate():\n",
    "            if not self.is_testing:\n",
    "                t = cleanup_method(t)\n",
    "            else:\n",
    "                if cleanup_method.__name__ != \"remove_na\":\n",
    "                    t = cleanup_method(t)\n",
    "\n",
    "        self.processed_data = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:16:17+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:43:48+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>brabi orange pk lconnexion ma tebech temchili ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:37:47+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>slm orange elyoumadet fourfi ta jour tantli ma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:00:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Neb orange</td>\n",
       "      <td>positive</td>\n",
       "      <td>2018-01-08T20:13:49+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>حزين</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-08T19:15:36+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>نسالكم ميغاا الله لا تربحكم انتم باش تربحوو ال...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T19:11:40+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Problème de connexion avec les sites internati...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-09T18:10:08+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>bon orange pk la connexion tbch temchi ken fac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T20:47:32+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>aslma orange belhy neb nareflach neetow barcha...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018-01-02T21:43:12+0000</td>\n",
       "      <td>https://www.facebook.com/298166859034_10155976...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            comment   emotion  \\\n",
       "0    0  عسلامة أورونج رقدت مخلي ال puce متاعي أورونج ق...  negative   \n",
       "1    1  اورونج نحب نقلكم عيشكم خاتر انتوما الوحدين\\nتت...  negative   \n",
       "2    2  brabi orange pk lconnexion ma tebech temchili ...  negative   \n",
       "3    3  slm orange elyoumadet fourfi ta jour tantli ma...  negative   \n",
       "4    4                                         Neb orange  positive   \n",
       "5    5                                               حزين  negative   \n",
       "6    6  نسالكم ميغاا الله لا تربحكم انتم باش تربحوو ال...  negative   \n",
       "7    7  Problème de connexion avec les sites internati...  negative   \n",
       "8    8  bon orange pk la connexion tbch temchi ken fac...  negative   \n",
       "9    9  aslma orange belhy neb nareflach neetow barcha...  negative   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2018-01-02T19:16:17+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "1  2018-01-02T19:43:48+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "2  2018-01-02T20:37:47+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "3  2018-01-02T19:00:49+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "4  2018-01-08T20:13:49+0000  https://www.facebook.com/298166859034_10155991...  \n",
       "5  2018-01-08T19:15:36+0000  https://www.facebook.com/298166859034_10155991...  \n",
       "6  2018-01-02T19:11:40+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "7  2018-01-09T18:10:08+0000  https://www.facebook.com/298166859034_10155990...  \n",
       "8  2018-01-02T20:47:32+0000  https://www.facebook.com/298166859034_10155976...  \n",
       "9  2018-01-02T21:43:12+0000  https://www.facebook.com/298166859034_10155976...  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Cleansing(data)\n",
    "data.cleanup(TwitterCleanuper())\n",
    "data.processed_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data\\\\four-column500v1.2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = pd.read_table('path to csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idx'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name =df.columns[0]\n",
    "col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterData_TokenStem(TwitterData_Cleansing):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"emotion\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"emotion\"]))\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"emotion\"] = tokenizer(row[\"emotion\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"emotion\"]\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('expected string or bytes-like object', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-221-9be3ff4aaf96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitterData_TokenStem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-220-698c92d855ad>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, tokenizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4260\u001b[0m                         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4261\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4262\u001b[1;33m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[0;32m   4263\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4264\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4359\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4360\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-220-698c92d855ad>\u001b[0m in \u001b[0;36mtokenize_row\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtokenize_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"emotion\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"emotion\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tokenized_text\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"emotion\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[0;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \"\"\"\n\u001b[0;32m     96\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;31m# Standard word tokenizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \"\"\"\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \"\"\"\n\u001b[1;32m-> 1283\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \"\"\"\n\u001b[0;32m   1313\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \"\"\"\n\u001b[0;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m     \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1287\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1288\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_tok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('expected string or bytes-like object', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "data = TwitterData_TokenStem(data)\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.idx:\n",
    "    words.update(data.processed_data.loc[idx, \"emotion\"])\n",
    "    words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['في_بيتنا',\n",
       " 'كل',\n",
       " 'شي',\n",
       " 'لما',\n",
       " 'تحتاجه',\n",
       " 'يضيع',\n",
       " '...',\n",
       " 'ادور',\n",
       " 'على',\n",
       " 'شاحن',\n",
       " 'فجأة',\n",
       " 'يختفي',\n",
       " '..لدرجة',\n",
       " 'اني',\n",
       " 'اسوي',\n",
       " 'نفسي',\n",
       " 'ادور',\n",
       " 'شيء']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize('في_بيتنا كل شي لما تحتاجه يضيع ...ادور على شاحن فجأة يختفي ..لدرجة اني اسوي نفسي ادور شيء ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
