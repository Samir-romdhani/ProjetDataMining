{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plotly configuration\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"emotion\", \"text\"])\n",
    "            self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"text\"],dtype={\"id\":\"int64\",\"text\":\"str\"},nrows=4000)\n",
    "            not_null_text = 1 ^ pd.isnull(self.data[\"text\"])\n",
    "            not_null_id = 1 ^ pd.isnull(self.data[\"id\"])\n",
    "            self.data = self.data.loc[not_null_id & not_null_text, :]\n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"data\\\\train.csv\")\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.processed_data\n",
    "neg = len(df[df[\"emotion\"] == \"negative\"])\n",
    "pos = len(df[df[\"emotion\"] == \"positive\"])\n",
    "neu = len(df[df[\"emotion\"] == \"neutral\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"negative\",\"neutral\",\"positive\"],\n",
    "        y=[neg, neu, pos],\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Sentiment type distribution in training set\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "negative     956\n",
       "neutral     2125\n",
       "positive    2888\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gR = df.groupby('emotion').size()\n",
    "print(type(gR))\n",
    "gR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2595f11b898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(gR.index, gR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-83-45b0a9a34ff1>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-83-45b0a9a34ff1>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    #print(w)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def words(stringIterable):\n",
    "    #upcast the argument to an iterator, if it's an iterator already, it stays the same\n",
    "    lineStream = iter(stringIterable)\n",
    "    for line in lineStream: #enumerate the lines\n",
    "        for word in line.split(): #further break them down\n",
    "            yield word\n",
    "for word in data.processed_data.text:\n",
    "    #print(word)\n",
    "    for w in words([word]):\n",
    "        #print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 102980), ('e', 48826), ('t', 43612), ('o', 38223), ('a', 38001)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.index:\n",
    "    words.update(data.processed_data.loc[idx, \"text\"])\n",
    "\n",
    "words.most_common(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "there\n",
      "how\n",
      "are\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "def words(stringIterable):\n",
    "    #upcast the argument to an iterator, if it's an iterator already, it stays the same\n",
    "    lineStream = iter(stringIterable)\n",
    "    for line in lineStream: #enumerate the lines\n",
    "        for word in line.split(): #further break them down\n",
    "            yield word\n",
    "listOfLines = ['hi there', 'how are you']\n",
    "for word in words(listOfLines):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Wordlist(TwitterData_TokenStem):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    whitelist = [\"n't\",\"not\"]\n",
    "    wordlist = []\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=3, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        import os\n",
    "        if os.path.isfile(\"data\\\\wordlist.csv\"):\n",
    "            word_df = pd.read_csv(\"data\\\\wordlist.csv\")\n",
    "            word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "            self.wordlist = list(word_df.loc[:, \"word\"])\n",
    "            return\n",
    "\n",
    "        words = Counter()\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"text\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"data\\\\wordlist.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-42bf40bde36b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                     \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                     random_state=seed)\n\u001b[0;32m      5\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bow' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=bow.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
